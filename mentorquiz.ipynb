{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c481227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57720815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'quiz1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9348\\187246267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the Excel file into a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'quiz1.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'usnews3.data.9 .SS (v5.0)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1525\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m     ) as handle:\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'quiz1.xlsx'"
     ]
    }
   ],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('quiz1.xlsx', sheet_name='usnews3.data.9 .SS (v5.0)')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef13c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36440737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are any duplicate colleges based on both name and state.\n",
    "\n",
    "is_duplicate = df.duplicated(subset=['College Name', 'State'])\n",
    "duplicated_rows = df[is_duplicate]\n",
    "duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics for the target variable Graduation Rate\n",
    "\n",
    "target_stats = df['Graduation rate'].describe()\n",
    "print(target_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbfde5",
   "metadata": {},
   "source": [
    "The maximum value of the target variable is 118 which is higher than the 100% rate that should be possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772ae74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(df['Graduation rate'], bins=25, edgecolor='k')\n",
    "plt.xlabel('Graduation Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Graduation Rates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45afc86f",
   "metadata": {},
   "source": [
    "The histogram of the target variable shows that there is one college above the 100% graduation rate now we will take a look at that college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32303a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Graduation rate'] == 118.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9702c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['College Name'] == 'Cazenovia College', 'Graduation rate'] = 57.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70c0ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Graduation rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b43a3c",
   "metadata": {},
   "source": [
    "Now graduation rate only goes to the maximum value of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92255f7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3fc3ae",
   "metadata": {},
   "source": [
    "Before dealing with null values I want to remove the rows that have nulls in the target column as imputing is not guaranteed to be an accurate depiction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687f4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Graduation rate'])\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c80f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group the data by the 'Public (1)/ Private (2)' column and calculate the mean graduation rate\n",
    "grouped = df.groupby('Public (1)/ Private (2)')\n",
    "mean_grad_rate = grouped['Graduation rate'].mean()\n",
    "\n",
    "# Plot the mean graduation rates\n",
    "labels = ['Public', 'Private']\n",
    "plt.bar(labels, mean_grad_rate)\n",
    "plt.xlabel('College Type')\n",
    "plt.ylabel('Mean Graduation Rate')\n",
    "plt.title('Mean Graduation Rate by College Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f274d26",
   "metadata": {},
   "source": [
    "College type will likely be a good indicator of graduation rate with Private college students graduating at an average rate over 10% higher than public universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f2dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Impute null values with column medians\n",
    "df_filled = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Check for remaining null values\n",
    "null_counts = df_filled.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acdf88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,10))\n",
    "plt.subplots_adjust(hspace=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832d107",
   "metadata": {},
   "source": [
    "# PCA Analysis for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a61a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"College Name\" and \"State\" columns from the DataFrame used for PCA\n",
    "df_pca = df_filled.drop([\"College Name\", \"State\"], axis=1)\n",
    "\n",
    "# Create separate variables for the \"College Name\" and \"State\" columns\n",
    "college_names = df_filled[\"College Name\"]\n",
    "states = df_filled[\"State\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_pca)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c11a13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot cumulative explained variance\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance by Number of Components')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67b9e74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot scatter plot of PCA components\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e50288",
   "metadata": {},
   "source": [
    "The scatter plot of the PCA components provides visual insights into the relationship between the data points in the reduced-dimensional space. In this case, the scatter plot shows the distribution and clustering of the data points based on their values in the first two principal components.\n",
    "\n",
    "The scatter plot appears to exhibit a parabolic or curved pattern, indicating a potential non-linear relationship among the data points. The curvature suggests that there may be complex interactions or higher-order patterns present in the data that are not easily captured by a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Print explained variance ratio for each component\n",
    "for i, variance_ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Component {i+1}: {variance_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b28e3f",
   "metadata": {},
   "source": [
    "Components 1 and 2 collectively explain approximately 53% of the total variance in the dataset. This indicates that these two components capture a significant portion of the variability present in the original features. The relatively high explained variance suggests that these components contain valuable information for predicting the target variable, graduation rate.\n",
    "\n",
    "On the other hand, components 3 and above contribute much less to the overall variance explained, with component 3 explaining less than 7% of the variance. This suggests that the additional components beyond the first two contribute relatively less information compared to the initial components. These components may capture more noise or less meaningful patterns in the data.\n",
    "\n",
    "In summary, components 1 and 2 capture a substantial amount of the variance in the dataset, while the remaining components contribute relatively less. By focusing on these important components, we can effectively reduce the dimensionality of the data while retaining key information for predicting graduation rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d7e7b",
   "metadata": {},
   "source": [
    "# Possible ML for Predicting Graduation Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94c71b",
   "metadata": {},
   "source": [
    "1) Polynomial Regression: Since the scatter plot exhibits a parabolic or curved pattern, polynomial regression can be explored as a model that can capture non-linear relationships. By including polynomial terms of the principal components as additional features, a polynomial regression model may better capture the non-linearities in the data.\n",
    "\n",
    "2) Random Forest Regression: Random forest regression is an ensemble learning model that can handle non-linear relationships effectively. It combines multiple decision trees to make predictions and can capture complex interactions and patterns in the data. By utilizing the principal components as input features, a random forest regression model may provide accurate predictions of graduation rates.\n",
    "\n",
    "3) Linear Regression: Despite the presence of non-linear patterns in the scatter plot, it is still worth considering a linear regression model as a baseline approach. By using the principal components as input features, we can build a linear regression model to estimate graduation rates. However, it is important to keep in mind that the linear regression model may not capture the full complexity of the underlying relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
